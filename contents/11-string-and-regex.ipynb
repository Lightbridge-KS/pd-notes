{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dcd49b5",
   "metadata": {},
   "source": [
    "# String/Regex Cheatsheet\n",
    "\n",
    "This notebook provides a comprehensive guide to string and regex operations in Python and Pandas, with practical examples and comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3de5afb",
   "metadata": {},
   "source": [
    "## Comparison Table: Python vs Pandas String Operations\n",
    "\n",
    "| Operation | Python Syntax | Pandas Syntax | Key Differences |\n",
    "|-----------|---------------|---------------|-----------------|\n",
    "| **Case Conversion** | `text.lower()` | `df['col'].str.lower()` | Pandas works on entire Series; Python on single string |\n",
    "| **String Length** | `len(text)` | `df['col'].str.len()` | Pandas returns Series; Python returns integer |\n",
    "| **Substring Check** | `\"abc\" in text` | `df['col'].str.contains(\"abc\")` | Pandas returns boolean Series; Python returns boolean |\n",
    "| **Start/End Check** | `text.startswith(\"ab\")` | `df['col'].str.startswith(\"ab\")` | Pandas vectorized across all rows |\n",
    "| **Replace Text** | `text.replace(\"old\", \"new\")` | `df['col'].str.replace(\"old\", \"new\")` | Pandas has `regex=True` parameter |\n",
    "| **Split String** | `text.split(\",\")` | `df['col'].str.split(\",\")` | Pandas can use `expand=True` for separate columns |\n",
    "| **Extract Substring** | `text[0:5]` | `df['col'].str[0:5]` or `df['col'].str.slice(0,5)` | Pandas has both indexing and slice method |\n",
    "| **Regex Search** | `re.search(pattern, text)` | `df['col'].str.extract(pattern)` | Pandas extracts to new columns automatically |\n",
    "| **Regex Find All** | `re.findall(pattern, text)` | `df['col'].str.findall(pattern)` | Pandas returns list in each cell |\n",
    "| **Regex Replace** | `re.sub(pattern, repl, text)` | `df['col'].str.replace(pattern, repl, regex=True)` | Pandas requires `regex=True` flag |\n",
    "| **String Concatenation** | `str1 + str2` | `df['col1'].str.cat(df['col2'])` | Pandas has special concatenation method |\n",
    "| **Null Handling** | Manual checking required | Automatic (skips NaN values) | Pandas handles missing data gracefully |\n",
    "| **Performance** | Single string operation | Vectorized operation | Pandas much faster for multiple strings |\n",
    "| **Return Type** | String or Match object | Series or DataFrame | Pandas preserves DataFrame structure |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dec99e",
   "metadata": {},
   "source": [
    "## When to Use Each Approach\n",
    "\n",
    "### Use Python String Methods When:\n",
    "- Working with individual strings or small datasets\n",
    "- Need maximum performance for single string operations  \n",
    "- Writing functions that process one string at a time\n",
    "- Working outside of pandas DataFrame context\n",
    "\n",
    "### Use Pandas String Methods When:\n",
    "- Working with DataFrame columns containing text\n",
    "- Need to apply operations to many strings at once\n",
    "- Want to maintain DataFrame structure in results\n",
    "- Need automatic handling of missing values (NaN)\n",
    "- Performing data cleaning and preprocessing tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b299aab",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook covered:\n",
    "\n",
    "1. **Python vs Pandas String Operations**: Understanding when to use each approach\n",
    "2. **Python Built-in String Methods**: Basic operations for individual strings\n",
    "3. **Pandas String Operations**: Vectorized operations using the `.str` accessor\n",
    "4. **Regex Operations**: Pattern matching and extraction in both Python and Pandas\n",
    "5. **Method Chaining**: Tidy-style programming for readable data transformations\n",
    "6. **Performance Tips**: Optimizing string operations for large datasets\n",
    "\n",
    "Key takeaways:\n",
    "\n",
    "- Use Python string methods for individual strings\n",
    "- Use Pandas `.str` accessor for DataFrame columns\n",
    "- Pandas handles missing values automatically\n",
    "- Method chaining creates readable, maintainable code\n",
    "- Consider performance optimizations for large datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6391718d",
   "metadata": {},
   "source": [
    "## Python Built-in String Operations\n",
    "\n",
    "Let's start with Python's built-in string methods for individual string manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d142182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Hello World\n",
      "Lower: hello world\n",
      "Upper: HELLO WORLD\n",
      "Title: Hello World\n",
      "Capitalize: Hello world\n",
      "Swapcase: hELLO wORLD\n"
     ]
    }
   ],
   "source": [
    "# Basic String Methods - Case Operations\n",
    "text = \"Hello World\"\n",
    "\n",
    "print(\"Original:\", text)\n",
    "print(\"Lower:\", text.lower())\n",
    "print(\"Upper:\", text.upper())\n",
    "print(\"Title:\", text.title())\n",
    "print(\"Capitalize:\", text.capitalize())\n",
    "print(\"Swapcase:\", text.swapcase())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9ead8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starts with 'Hello': True\n",
      "Ends with 'World': True\n",
      "Is digit: False\n",
      "Is alpha: False\n",
      "Is alphanumeric: False\n",
      "Is space: False\n"
     ]
    }
   ],
   "source": [
    "# String Checking Methods\n",
    "text = \"Hello World\"\n",
    "\n",
    "print(\"Starts with 'Hello':\", text.startswith(\"Hello\"))\n",
    "print(\"Ends with 'World':\", text.endswith(\"World\"))\n",
    "print(\"Is digit:\", text.isdigit())\n",
    "print(\"Is alpha:\", text.isalpha())  # False because contains space\n",
    "print(\"Is alphanumeric:\", text.isalnum())  # False because contains space\n",
    "print(\"Is space:\", text.isspace())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1571f9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find 'World': 6\n",
      "Find last 'l': 9\n",
      "Count 'l': 3\n",
      "Index of 'World': 6\n"
     ]
    }
   ],
   "source": [
    "# String Searching and Counting\n",
    "text = \"Hello World\"\n",
    "\n",
    "print(\"Find 'World':\", text.find(\"World\"))  # Returns index\n",
    "print(\"Find last 'l':\", text.rfind(\"l\"))\n",
    "print(\"Count 'l':\", text.count(\"l\"))\n",
    "\n",
    "# Note: index() raises error if not found, find() returns -1\n",
    "try:\n",
    "    print(\"Index of 'World':\", text.index(\"World\"))\n",
    "except ValueError as e:\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daf8beb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: '  Hello World  '\n",
      "Replace 'World' with 'Python':   Hello Python  \n",
      "Strip whitespace: 'Hello World'\n",
      "Left strip: 'Hello World  '\n",
      "Right strip: '  Hello World'\n",
      "Strip specific chars: 'ello Worl'\n"
     ]
    }
   ],
   "source": [
    "# String Modification\n",
    "text = \"  Hello World  \"\n",
    "\n",
    "print(\"Original:\", repr(text))\n",
    "print(\"Replace 'World' with 'Python':\", text.replace(\"World\", \"Python\"))\n",
    "print(\"Strip whitespace:\", repr(text.strip()))\n",
    "print(\"Left strip:\", repr(text.lstrip()))\n",
    "print(\"Right strip:\", repr(text.rstrip()))\n",
    "print(\"Strip specific chars:\", repr(text.strip().strip(\"Hd\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2b121f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split by space: ['Hello', 'World']\n",
      "Split by 'l': ['He', '', 'o Wor', 'd']\n",
      "Join with dash: Hello-World\n",
      "F-string: Name: John, Age: 25\n",
      "Format method: Name: John, Age: 25\n"
     ]
    }
   ],
   "source": [
    "# String Splitting and Joining\n",
    "text = \"Hello World\"\n",
    "\n",
    "print(\"Split by space:\", text.split())\n",
    "print(\"Split by 'l':\", text.split(\"l\"))\n",
    "print(\"Join with dash:\", \"-\".join([\"Hello\", \"World\"]))\n",
    "\n",
    "# String formatting\n",
    "name, age = \"John\", 25\n",
    "print(\"F-string:\", f\"Name: {name}, Age: {age}\")\n",
    "print(\"Format method:\", \"Name: {}, Age: {}\".format(name, age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b788ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First character: H\n",
      "Last character: d\n",
      "First 5 chars: Hello\n",
      "From index 6: World\n",
      "Reverse: dlroW olleH\n",
      "Every 2nd char: HloWrd\n"
     ]
    }
   ],
   "source": [
    "# String Slicing and Indexing\n",
    "text = \"Hello World\"\n",
    "\n",
    "print(\"First character:\", text[0])\n",
    "print(\"Last character:\", text[-1])\n",
    "print(\"First 5 chars:\", text[0:5])\n",
    "print(\"From index 6:\", text[6:])\n",
    "print(\"Reverse:\", text[::-1])\n",
    "print(\"Every 2nd char:\", text[::2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc8b864",
   "metadata": {},
   "source": [
    "## Pandas String Operations (`.str` accessor)\n",
    "\n",
    "Now let's explore Pandas string operations which work on entire Series/columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63f273e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample DataFrame:\n",
      "          name           email\n",
      "0     John Doe  john@email.com\n",
      "1   jane smith  jane@gmail.com\n",
      "2  Bob Johnson   bob@yahoo.com\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'name': ['John Doe', 'jane smith', 'Bob Johnson'],\n",
    "    'email': ['john@email.com', 'jane@gmail.com', 'bob@yahoo.com']\n",
    "})\n",
    "\n",
    "print(\"Sample DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a323c4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original names:\n",
      "0       John Doe\n",
      "1     jane smith\n",
      "2    Bob Johnson\n",
      "Name: name, dtype: object\n",
      "\n",
      "Lowercase:\n",
      "0       john doe\n",
      "1     jane smith\n",
      "2    bob johnson\n",
      "Name: name, dtype: object\n",
      "\n",
      "Uppercase:\n",
      "0       JOHN DOE\n",
      "1     JANE SMITH\n",
      "2    BOB JOHNSON\n",
      "Name: name, dtype: object\n",
      "\n",
      "Title case:\n",
      "0       John Doe\n",
      "1     Jane Smith\n",
      "2    Bob Johnson\n",
      "Name: name, dtype: object\n",
      "\n",
      "Capitalize:\n",
      "0       John doe\n",
      "1     Jane smith\n",
      "2    Bob johnson\n",
      "Name: name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Case Operations with Pandas\n",
    "print(\"Original names:\")\n",
    "print(df['name'])\n",
    "print(\"\\nLowercase:\")\n",
    "print(df['name'].str.lower())\n",
    "print(\"\\nUppercase:\")\n",
    "print(df['name'].str.upper())\n",
    "print(\"\\nTitle case:\")\n",
    "print(df['name'].str.title())\n",
    "print(\"\\nCapitalize:\")\n",
    "print(df['name'].str.capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fb3523e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names starting with 'J':\n",
      "0     True\n",
      "1    False\n",
      "2    False\n",
      "Name: name, dtype: bool\n",
      "\n",
      "Emails ending with '.com':\n",
      "0    True\n",
      "1    True\n",
      "2    True\n",
      "Name: email, dtype: bool\n",
      "\n",
      "Check if all digits:\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "Name: name, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# String Checking with Pandas\n",
    "print(\"Names starting with 'J':\")\n",
    "print(df['name'].str.startswith('J'))\n",
    "print(\"\\nEmails ending with '.com':\")\n",
    "print(df['email'].str.endswith('.com'))\n",
    "print(\"\\nCheck if all digits:\")\n",
    "print(df['name'].str.isdigit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10af229d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of names:\n",
      "0     8\n",
      "1    10\n",
      "2    11\n",
      "Name: name, dtype: int64\n",
      "\n",
      "Count of 'o' in names:\n",
      "0    2\n",
      "1    0\n",
      "2    3\n",
      "Name: name, dtype: int64\n",
      "\n",
      "Count of 'o' in emails:\n",
      "0    2\n",
      "1    1\n",
      "2    4\n",
      "Name: email, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# String Length and Counting\n",
    "print(\"Length of names:\")\n",
    "print(df['name'].str.len())\n",
    "print(\"\\nCount of 'o' in names:\")\n",
    "print(df['name'].str.count('o'))\n",
    "print(\"\\nCount of 'o' in emails:\")\n",
    "print(df['email'].str.count('o'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c94219ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replace spaces with underscores:\n",
      "0       John_Doe\n",
      "1     jane_smith\n",
      "2    Bob_Johnson\n",
      "Name: name, dtype: object\n",
      "\n",
      "Extract first 4 characters of email:\n",
      "0    john\n",
      "1    jane\n",
      "2    bob@\n",
      "Name: email, dtype: object\n",
      "\n",
      "Replace first 4 characters with 'USER':\n",
      "0    USER@email.com\n",
      "1    USER@gmail.com\n",
      "2     USERyahoo.com\n",
      "Name: email, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# String Modification with Pandas\n",
    "print(\"Replace spaces with underscores:\")\n",
    "print(df['name'].str.replace(' ', '_'))\n",
    "print(\"\\nExtract first 4 characters of email:\")\n",
    "print(df['email'].str.slice(0, 4))\n",
    "print(\"\\nReplace first 4 characters with 'USER':\")\n",
    "print(df['email'].str.slice_replace(0, 4, 'USER'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efa3f2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split names (returns lists):\n",
      "0       [John, Doe]\n",
      "1     [jane, smith]\n",
      "2    [Bob, Johnson]\n",
      "Name: name, dtype: object\n",
      "\n",
      "Split names into separate columns:\n",
      "      0        1\n",
      "0  John      Doe\n",
      "1  jane    smith\n",
      "2   Bob  Johnson\n",
      "\n",
      "Split emails by '@':\n",
      "      0          1\n",
      "0  john  email.com\n",
      "1  jane  gmail.com\n",
      "2   bob  yahoo.com\n"
     ]
    }
   ],
   "source": [
    "# String Splitting with Pandas\n",
    "print(\"Split names (returns lists):\")\n",
    "print(df['name'].str.split())\n",
    "print(\"\\nSplit names into separate columns:\")\n",
    "print(df['name'].str.split(' ', expand=True))\n",
    "print(\"\\nSplit emails by '@':\")\n",
    "print(df['email'].str.split('@', expand=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5dc9981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenate name and email:\n",
      "0      John Doe - john@email.com\n",
      "1    jane smith - jane@gmail.com\n",
      "2    Bob Johnson - bob@yahoo.com\n",
      "Name: name, dtype: object\n",
      "\n",
      "Concatenate with custom separator:\n",
      "0      John Doe | Email: john@email.com\n",
      "1    jane smith | Email: jane@gmail.com\n",
      "2    Bob Johnson | Email: bob@yahoo.com\n",
      "Name: name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# String Concatenation with Pandas\n",
    "print(\"Concatenate name and email:\")\n",
    "print(df['name'].str.cat(df['email'], sep=' - '))\n",
    "print(\"\\nConcatenate with custom separator:\")\n",
    "print(df['name'].str.cat(df['email'], sep=' | Email: '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879a5490",
   "metadata": {},
   "source": [
    "## Advanced Pandas String Operations\n",
    "\n",
    "Let's explore more advanced features like extraction, filtering, and indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df4ed404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract username and domain from email:\n",
      "      0      1\n",
      "0  john  email\n",
      "1  jane  gmail\n",
      "2   bob  yahoo\n",
      "\n",
      "Extract first and last name:\n",
      "      0        1\n",
      "0  John      Doe\n",
      "1  jane    smith\n",
      "2   Bob  Johnson\n"
     ]
    }
   ],
   "source": [
    "# Extract parts of strings using regex\n",
    "print(\"Extract username and domain from email:\")\n",
    "extracted = df['email'].str.extract(r'([^@]+)@([^.]+)')\n",
    "print(extracted)\n",
    "\n",
    "print(\"\\nExtract first and last name:\")\n",
    "name_parts = df['name'].str.extract(r'(\\w+)\\s+(\\w+)')\n",
    "print(name_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07975ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter rows with 'John' in name:\n",
      "0     True\n",
      "1    False\n",
      "2     True\n",
      "Name: name, dtype: bool\n",
      "\n",
      "Rows containing 'John':\n",
      "          name           email\n",
      "0     John Doe  john@email.com\n",
      "2  Bob Johnson   bob@yahoo.com\n",
      "\n",
      "Filter emails containing 'gmail' or 'yahoo':\n",
      "          name           email\n",
      "1   jane smith  jane@gmail.com\n",
      "2  Bob Johnson   bob@yahoo.com\n"
     ]
    }
   ],
   "source": [
    "# String contains for boolean indexing\n",
    "print(\"Filter rows with 'John' in name:\")\n",
    "john_filter = df['name'].str.contains('John')\n",
    "print(john_filter)\n",
    "print(\"\\nRows containing 'John':\")\n",
    "print(df[john_filter])\n",
    "\n",
    "print(\"\\nFilter emails containing 'gmail' or 'yahoo':\")\n",
    "email_filter = df['email'].str.contains('gmail|yahoo')\n",
    "print(df[email_filter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56ad1e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First character of names:\n",
      "0    J\n",
      "1    j\n",
      "2    B\n",
      "Name: name, dtype: object\n",
      "\n",
      "Last character of names:\n",
      "0    e\n",
      "1    h\n",
      "2    n\n",
      "Name: name, dtype: object\n",
      "\n",
      "First 4 characters of emails:\n",
      "0    john\n",
      "1    jane\n",
      "2    bob@\n",
      "Name: email, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# String indexing and slicing with Pandas\n",
    "print(\"First character of names:\")\n",
    "print(df['name'].str[0])\n",
    "print(\"\\nLast character of names:\")\n",
    "print(df['name'].str[-1])\n",
    "print(\"\\nFirst 4 characters of emails:\")\n",
    "print(df['email'].str[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f27e0c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left pad names with '*':\n",
      "0    *******John Doe\n",
      "1    *****jane smith\n",
      "2    ****Bob Johnson\n",
      "Name: name, dtype: object\n",
      "\n",
      "Center align names:\n",
      "0    ----John Doe---\n",
      "1    ---jane smith--\n",
      "2    --Bob Johnson--\n",
      "Name: name, dtype: object\n",
      "\n",
      "Right justify names:\n",
      "0    .......John Doe\n",
      "1    .....jane smith\n",
      "2    ....Bob Johnson\n",
      "Name: name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Padding and alignment\n",
    "print(\"Left pad names with '*':\")\n",
    "print(df['name'].str.pad(width=15, side='left', fillchar='*'))\n",
    "print(\"\\nCenter align names:\")\n",
    "print(df['name'].str.center(15, fillchar='-'))\n",
    "print(\"\\nRight justify names:\")\n",
    "print(df['name'].str.rjust(15, fillchar='.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9de361c",
   "metadata": {},
   "source": [
    "## Regex Operations\n",
    "\n",
    "Let's explore regular expression operations in both Python and Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b1f1fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: Contact: john@email.com or call 123-456-7890\n",
      "\n",
      "Find phone number:\n",
      "123-456-7890\n",
      "\n",
      "Find all email addresses:\n",
      "['john@email.com']\n",
      "\n",
      "Replace phone number:\n",
      "Contact: john@email.com or call XXX-XXX-XXXX\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Python re module examples\n",
    "text = \"Contact: john@email.com or call 123-456-7890\"\n",
    "\n",
    "print(\"Original text:\", text)\n",
    "print(\"\\nFind phone number:\")\n",
    "phone_match = re.search(r'\\d{3}-\\d{3}-\\d{4}', text)\n",
    "print(phone_match.group() if phone_match else \"Not found\")\n",
    "\n",
    "print(\"\\nFind all email addresses:\")\n",
    "emails = re.findall(r'\\w+@\\w+\\.\\w+', text)\n",
    "print(emails)\n",
    "\n",
    "print(\"\\nReplace phone number:\")\n",
    "masked_text = re.sub(r'\\d{3}-\\d{3}-\\d{4}', 'XXX-XXX-XXXX', text)\n",
    "print(masked_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92e5334a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full match: john@email.com\n",
      "Username: john\n",
      "Domain: email\n",
      "Extension: com\n",
      "All groups: ('john', 'email', 'com')\n"
     ]
    }
   ],
   "source": [
    "# Groups and capturing with regex\n",
    "text = \"Contact: john@email.com or call 123-456-7890\"\n",
    "\n",
    "match = re.search(r'(\\w+)@(\\w+)\\.(\\w+)', text)\n",
    "if match:\n",
    "    print(\"Full match:\", match.group(0))\n",
    "    print(\"Username:\", match.group(1))\n",
    "    print(\"Domain:\", match.group(2))\n",
    "    print(\"Extension:\", match.group(3))\n",
    "    print(\"All groups:\", match.groups())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93479cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text data:\n",
      "                     text\n",
      "0  Contact john@email.com\n",
      "1       Call 123-456-7890\n",
      "2   Visit www.example.com\n",
      "\n",
      "Extract email addresses:\n",
      "                0\n",
      "0  john@email.com\n",
      "1             NaN\n",
      "2             NaN\n",
      "\n",
      "Find all numbers:\n",
      "            0\n",
      "  match      \n",
      "1 0       123\n",
      "  1       456\n",
      "  2      7890\n"
     ]
    }
   ],
   "source": [
    "# Pandas regex operations\n",
    "df_text = pd.DataFrame({\n",
    "    'text': ['Contact john@email.com', 'Call 123-456-7890', 'Visit www.example.com']\n",
    "})\n",
    "\n",
    "print(\"Sample text data:\")\n",
    "print(df_text)\n",
    "\n",
    "print(\"\\nExtract email addresses:\")\n",
    "emails = df_text['text'].str.extract(r'(\\w+@\\w+\\.\\w+)')\n",
    "print(emails)\n",
    "\n",
    "print(\"\\nFind all numbers:\")\n",
    "numbers = df_text['text'].str.extractall(r'(\\d+)')\n",
    "print(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa1a7609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contains phone pattern:\n",
      "0    False\n",
      "1     True\n",
      "2    False\n",
      "Name: text, dtype: bool\n",
      "\n",
      "Matches 'Contact' from start:\n",
      "0     True\n",
      "1    False\n",
      "2    False\n",
      "Name: text, dtype: bool\n",
      "\n",
      "Find all words:\n",
      "0    [Contact, john, email, com]\n",
      "1         [Call, 123, 456, 7890]\n",
      "2     [Visit, www, example, com]\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Boolean operations with regex in Pandas\n",
    "print(\"Contains phone pattern:\")\n",
    "print(df_text['text'].str.contains(r'\\d{3}-\\d{3}-\\d{4}'))\n",
    "\n",
    "print(\"\\nMatches 'Contact' from start:\")\n",
    "print(df_text['text'].str.match(r'Contact.*'))\n",
    "\n",
    "print(\"\\nFind all words:\")\n",
    "words = df_text['text'].str.findall(r'\\w+')\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b0eedd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replace phone numbers with 'PHONE':\n",
      "0    Contact john@email.com\n",
      "1                Call PHONE\n",
      "2     Visit www.example.com\n",
      "Name: text, dtype: object\n",
      "\n",
      "Replace email format using groups:\n",
      "0    Contact john_AT_email.com\n",
      "1            Call 123-456-7890\n",
      "2        Visit www.example.com\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Replace with regex in Pandas\n",
    "print(\"Replace phone numbers with 'PHONE':\")\n",
    "replaced = df_text['text'].str.replace(r'\\d{3}-\\d{3}-\\d{4}', 'PHONE', regex=True)\n",
    "print(replaced)\n",
    "\n",
    "print(\"\\nReplace email format using groups:\")\n",
    "email_replaced = df_text['text'].str.replace(r'(\\w+)@(\\w+)', r'\\1_AT_\\2', regex=True)\n",
    "print(email_replaced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b4b3ef",
   "metadata": {},
   "source": [
    "## Common Regex Patterns\n",
    "\n",
    "Here are some useful regex patterns for common data cleaning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "971addcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EMAIL pattern: ^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\n",
      "  ✓ Matches: john@email.com\n",
      "\n",
      "PHONE_US pattern: \\d{3}-\\d{3}-\\d{4}\n",
      "  ✓ Matches: 123-456-7890\n",
      "\n",
      "URL pattern: https?://(?:[-\\w.])+(?:\\:[0-9]+)?(?:/(?:[\\w/_.])*(?:\\?(?:[\\w&=%.])*)?(?:\\#(?:[\\w.])*)?)?\n",
      "  ✓ Matches: https://www.example.com\n",
      "\n",
      "DATE_ISO pattern: \\d{4}-\\d{2}-\\d{2}\n",
      "  ✓ Matches: 2023-12-25\n",
      "\n",
      "DATE_US pattern: \\d{1,2}/\\d{1,2}/\\d{4}\n",
      "  ✓ Matches: 12/25/2023\n",
      "\n",
      "INTEGER pattern: ^-?\\d+$\n",
      "  ✓ Matches: -123\n",
      "\n",
      "FLOAT pattern: ^-?\\d+\\.?\\d*$\n",
      "  ✓ Matches: -123\n",
      "  ✓ Matches: 3.14159\n"
     ]
    }
   ],
   "source": [
    "# Common regex patterns\n",
    "patterns = {\n",
    "    'email': r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$',\n",
    "    'phone_us': r'\\d{3}-\\d{3}-\\d{4}',\n",
    "    'url': r'https?://(?:[-\\w.])+(?:\\:[0-9]+)?(?:/(?:[\\w/_.])*(?:\\?(?:[\\w&=%.])*)?(?:\\#(?:[\\w.])*)?)?',\n",
    "    'date_iso': r'\\d{4}-\\d{2}-\\d{2}',  # YYYY-MM-DD\n",
    "    'date_us': r'\\d{1,2}/\\d{1,2}/\\d{4}',  # MM/DD/YYYY\n",
    "    'integer': r'^-?\\d+$',\n",
    "    'float': r'^-?\\d+\\.?\\d*$'\n",
    "}\n",
    "\n",
    "# Test some patterns\n",
    "test_strings = [\n",
    "    'john@email.com',\n",
    "    '123-456-7890',\n",
    "    'https://www.example.com',\n",
    "    '2023-12-25',\n",
    "    '12/25/2023',\n",
    "    '-123',\n",
    "    '3.14159'\n",
    "]\n",
    "\n",
    "for pattern_name, pattern in patterns.items():\n",
    "    print(f\"\\n{pattern_name.upper()} pattern: {pattern}\")\n",
    "    for test_str in test_strings:\n",
    "        if re.match(pattern, test_str):\n",
    "            print(f\"  ✓ Matches: {test_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72be56d4",
   "metadata": {},
   "source": [
    "## Method Chaining (Pandas Tidy Style)\n",
    "\n",
    "Following the R tidyverse style, we can chain pandas operations for clean, readable code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09563fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "           name           email\n",
      "0    John Doe    john@email.com\n",
      "1    JANE SMITH  jane@gmail.com\n",
      "2   bob johnson   bob@yahoo.com\n",
      "\n",
      "Cleaned and filtered result:\n",
      "         name           email  name_clean domain  has_gmail\n",
      "0  JANE SMITH  jane@gmail.com  Jane Smith  gmail       True\n"
     ]
    }
   ],
   "source": [
    "# Example of method chaining for string operations\n",
    "df_demo = pd.DataFrame({\n",
    "    'name': ['  John Doe  ', 'JANE SMITH', 'bob johnson'],\n",
    "    'email': ['john@email.com', 'jane@gmail.com', 'bob@yahoo.com']\n",
    "})\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df_demo)\n",
    "\n",
    "# Method chaining for data cleaning\n",
    "result = (df_demo\n",
    "    .assign(\n",
    "        name_clean = lambda x: x['name'].str.strip().str.title(),\n",
    "        domain = lambda x: x['email'].str.extract(r'@(\\w+)\\.'),\n",
    "        has_gmail = lambda x: x['email'].str.contains('gmail')\n",
    "    )\n",
    "    .query('has_gmail == True')\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"\\nCleaned and filtered result:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca597ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex transformation result:\n",
      "    name_clean username domain  is_gmail  name_length\n",
      "0     John Doe     john  email     False            8\n",
      "1   Jane Smith     jane  gmail      True           10\n",
      "2  Bob Johnson      bob  yahoo     False           11\n"
     ]
    }
   ],
   "source": [
    "# More complex chaining example\n",
    "complex_result = (df_demo\n",
    "    .assign(\n",
    "        # Clean names\n",
    "        name_clean = lambda x: (x['name']\n",
    "                               .str.strip()\n",
    "                               .str.lower()\n",
    "                               .str.title()),\n",
    "        \n",
    "        # Extract email parts\n",
    "        username = lambda x: x['email'].str.extract(r'([^@]+)@')[0],\n",
    "        domain = lambda x: x['email'].str.extract(r'@([^.]+)\\.')[0],\n",
    "        \n",
    "        # Create flags\n",
    "        is_gmail = lambda x: x['email'].str.contains('gmail'),\n",
    "        name_length = lambda x: x['name_clean'].str.len()\n",
    "    )\n",
    "    .filter(['name_clean', 'username', 'domain', 'is_gmail', 'name_length'])\n",
    ")\n",
    "\n",
    "print(\"Complex transformation result:\")\n",
    "print(complex_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239f9757",
   "metadata": {},
   "source": [
    "## Performance Tips\n",
    "\n",
    "Here are some tips for optimizing string operations with large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a081d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large DataFrame shape: (10000, 2)\n",
      "\n",
      "Memory usage before categorical conversion:\n",
      "Category column: 550132 bytes\n",
      "Memory usage after categorical conversion:\n",
      "Category column: 10405 bytes\n"
     ]
    }
   ],
   "source": [
    "# Performance demonstration\n",
    "import numpy as np\n",
    "\n",
    "# Create larger sample data\n",
    "np.random.seed(42)\n",
    "large_df = pd.DataFrame({\n",
    "    'category': np.random.choice(['Type A', 'Type B', 'Type C'], 10000),\n",
    "    'text': ['Sample text ' + str(i) for i in range(10000)]\n",
    "})\n",
    "\n",
    "print(\"Large DataFrame shape:\", large_df.shape)\n",
    "\n",
    "# 1. Use categorical data for repeated strings\n",
    "print(\"\\nMemory usage before categorical conversion:\")\n",
    "print(f\"Category column: {large_df['category'].memory_usage(deep=True)} bytes\")\n",
    "\n",
    "large_df['category'] = large_df['category'].astype('category')\n",
    "print(\"Memory usage after categorical conversion:\")\n",
    "print(f\"Category column: {large_df['category'].memory_usage(deep=True)} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d909eff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using vectorized string operations:\n",
      "2.97 ms ± 60.4 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "\n",
      "Efficient chaining:\n",
      "6.2 ms ± 225 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "\n",
      "Filtering before operations:\n",
      "Filtered DataFrame shape: (10000, 2)\n"
     ]
    }
   ],
   "source": [
    "# 2. Compile regex patterns for repeated use\n",
    "pattern = re.compile(r'\\d+')\n",
    "\n",
    "# Demonstrate vectorized operations\n",
    "print(\"Using vectorized string operations:\")\n",
    "%timeit large_df['text'].str.contains(pattern)\n",
    "\n",
    "# 3. Chain operations efficiently\n",
    "print(\"\\nEfficient chaining:\")\n",
    "%timeit (large_df['text'].str.lower().str.strip().str.replace(r'\\s+', ' ', regex=True))\n",
    "\n",
    "# 4. Filter before operations when possible\n",
    "print(\"\\nFiltering before operations:\")\n",
    "filtered_df = large_df[large_df['text'].notna()]\n",
    "print(f\"Filtered DataFrame shape: {filtered_df.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
